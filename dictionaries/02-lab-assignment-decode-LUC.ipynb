{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GISC 420 T1 2022\n",
    "# **Assignment 3 Data processing using `dictionary` objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to run this cell to get things setup\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you are asked to use a data dictionary to perform relatively complicated processing of a data set to make it more useful for mapping and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background information\n",
    "The dataset we will be using is the Land Resource Inventory (LRI) which was digitized in the 1970s and includes extensive information on land use capability (or suitability), erosion,\n",
    "geology, soils, and vegetation. LRI is a valuable resource for any work looking into changes in\n",
    "land use over time. However, the form in which the attribute data for this database was recorded is a product of a time when computer memory and storage was at a premium. As a result very complex information about each map unit is recorded in a format that presents difficulties for present day users of the data interested in making even simple land capability, vegetation, soil or geological maps.\n",
    "\n",
    "The particular data attribute we are interested in is Landuse Capability (LUC) which has been encoded in the format\n",
    "\n",
    "    abcc+abcc\n",
    "    \n",
    "where the second part of this code may not always be present. The first four characters encode the dominant landuse capability assessment, and the second set of four (after the `+` sign) encode a subdominant capability where this has been assessed.\n",
    "\n",
    "The characters in the assessment code are interpreted as explained below. First, the letter `a` denotes the Landuse Class as tabulated below\n",
    "\n",
    "`a` | Landuse class\n",
    ":--:|:-------------\n",
    "1 2 3 or 4 | Arable\n",
    "5 6 or 7 | Non-arable\n",
    "8 | Protected\n",
    "\n",
    "Next the letter `b` denotes the Landuse limitation\n",
    "\n",
    "`b` | Landuse limitation\n",
    ":--:|:------------------\n",
    "c | Climate\n",
    "e | Erosion\n",
    "s | Soil\n",
    "w | Wetness\n",
    "\n",
    "Finally, the two characters `cc` are a two digit number ranking and associating various categories of land use suitability. Detailed interpretation of the number is beyond our scope in this assignment. Details can be found in:\n",
    "\n",
    "+ Noble, K. E., 1985. [*Land Use Capability Classification of the Southern Hawkeâ€™s Bay-Waiarapa\n",
    "Region: A Bulletin to Accompany New Zealand Land Resource Inventory Worksheets*](https://digitallibrary.landcareresearch.co.nz/digital/api/collection/p20022coll27/id/21/download). Land\n",
    "Resource Group Soil Conservation Centre, Aokautere, Ministry of Works and Development,\n",
    "Palmerston North.\n",
    "\n",
    "The four character `abcc` code may appear twice separated by a `+` character, in which\n",
    "case the first set of four indicates the dominant land use capability assessment and the second\n",
    "set a subdominant assessment.\n",
    "\n",
    "Finally, 'non-normal' land units are coded as follows\n",
    "\n",
    "Code | Meaning\n",
    ":----|:-------\n",
    "estu | Estuary\n",
    "ice | Ice\n",
    "lake | Lake\n",
    "quar | Quarries/mines\n",
    "rive | River\n",
    "town | Town/urban\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what's the problem?\n",
    "So, for example the code\n",
    "\n",
    "    3e 7+5e 5\n",
    "    \n",
    "decodes to\n",
    "\n",
    "    Dominant class:          Arable\n",
    "    Dominant limitation:     Erosion\n",
    "    Dominant suitability:    7\n",
    "    Subdominant class:       Non-arable\n",
    "    Subdominant limitation:  Erosion\n",
    "    Subdominant suitability: 5\n",
    "    \n",
    "That's a lot of information encoded in a single attribute, and you can maybe see why we would want to break it out into new variables in the dataset.\n",
    "\n",
    "To see the problem even more clearly, we will read in a sample of the data (this is a national dataset, but it's useful to look at just a subset to get the idea)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = geopandas.read_file('wairarapa_s_hawkes_bay.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.plot(column='LUC', figsize=(8,11), linestyle='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty map, but to get some idea of the problem, take a close look at the `LUC` column in the data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the 6773 rows in this table, there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(d.LUC)) # using conversion from a list to a set to count unique cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes... that's right, 105, unique codes! Although it is clear from the quick map we made above that there is useful spatial structure in these data, mapping and visulization is made difficult by so much information being summarised in a single (complex) encoding.\n",
    "\n",
    "What we are aiming for is a way to unpack this information, per the tables in the previous section into  new variables each showing dominant and subdominant landuse class, landuse limitation, and landuse ranking. \\[You can probably see that there's a similar problem lurking in the information contained in the `ROCK` and `SOIL` variables, but we'll leave that for some other time.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before continuing we'll read an even smaller dataset for testing\n",
    "d = geopandas.read_file('sample_lri.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An outline solution\n",
    "There are probably a hundred different ways to approach this problem. I'm going to outline one approach, which you can follow. \n",
    "\n",
    "If you are feeling adventurous (and confident) feel free to tackle it in a different way. Below is how I would do it.\n",
    "\n",
    "**First** write a function (or functions) that takes as input a LUC code, and depending on the parameters, returns dominant or subdominant landuse class, landuse limitation or landuse suitability&mdash;that's six different possible outcomes. It is totally fine if we end up with six smaller simpler functions, each of them capable of decoding a single new variable (i.e. dominant/subdominant and landuse class/limitation/suitability)\n",
    "\n",
    "**Second** ... well... that's kind of the whole plan! Essentially apply the function(s) to the input data six times to extract the required attributes into six new data columns in the dataframe. \n",
    "\n",
    "The question is how to execute it.\n",
    "\n",
    "Here are some things to consider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries as translators\n",
    "We've seen in the book how a dictionary can be used to translate between two languages, or in our situation how it can be used to map keys in the encoded data to values that we want in our output data. For example, if we had a dictionary with\n",
    "\n",
    "    dictionary['town'] = 'Town/urban'\n",
    "    \n",
    "then it can do a small bit of the translation we need.  Similarly, provided we know that we are trying to determine the landuse class, a dictionary that decodes an input `1`, `2`, `3`, or `4` as `Arable` would also be useful. Same goes for one that can handle the landuse limitation. The suitability is a bit different. Since those are two digit numeric codes it's fine just to retain them as numeric codes (there is some trickiness here dealing with NA values if we want to make useful maps, but that is a detail).\n",
    "\n",
    "So... I suggest that the first thing to do is build a dictionary that can do most of the decoding for us. Start work on this in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Build your translator `dict` here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup a dictionary to do the hard work of the decoding\n",
    "## It's OK if it can only handle some cases to begin with\n",
    "## It's also OK to make two or three simple dictionaries \n",
    "## rather than one big complicated one\n",
    "## Look at the tables in the Background information section \n",
    "## back at the top of this notebook for inspiration\n",
    "\n",
    "## I've made a start on one of them for you below\n",
    "non_normals = {'estu': 'Estuary'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new variables to a `GeoDataFrame`\n",
    "Once you have decoded a set of values, you'll want to add them to the data table. This is pretty easy, as it turns out. The geodataframe behaves a bit like a dictionary, with each column an entry keyed by its name. We simply do\n",
    "\n",
    "    d['NewVariableName'] = ...\n",
    "    \n",
    "where we obviously need to fill in the `...` with some result from a function.\n",
    "\n",
    "This is where `geopandas` is a big help. Instead of looping through every value in the `LUC` column of the dataset if we have some function (say) `decode_landuse_class` then we can do this:\n",
    "\n",
    "    d.LUC.apply(decode_landuse_class)\n",
    "    \n",
    "to apply it to the `LUC` codes.  So in this case\n",
    "\n",
    "    d['DOM_LUCLASS`] = d.LUC.apply(decode_landuse_class)\n",
    "    \n",
    "would do the trick. That suggests we need some functions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simple functions for each of the six possible decodings\n",
    "We want to decode the `LUC` codes to six different new variables, so at least to begin, this suggests making six (simple) functions that can take a `LUC` code and convert it to a value appropriate for whichever of the six new variables we want. So for example, you might have a function `decode_dom_class(code)` and another `decode_dom_limitation(code)` and so on.\n",
    "    \n",
    "There is likely to be scope for combining functions given that the dominant and subdominant assessment codes are the same (each is made up of four characters encoded identically, just before and after the `+` sign). But this is a refinement. To begin with, writing six simple functions that handle just one of the decoding operations will be perfectly fine.\n",
    "\n",
    "Again, I've made a start below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return the dominant landuse class\n",
    "# given a LUC code\n",
    "def dom_landuse(code):\n",
    "    if code in non_normals:\n",
    "        return non_normals[code]\n",
    "    else:\n",
    "        return lu_classes[code[0]] # this won't work yet, because 'lu_classes' dict does not exist\n",
    "\n",
    "## You'll need to write functions for the other new variables also "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Add to the code below to do all the needed conversions**\n",
    "The example below shows how this would work for just one of the codes. You'll need to write short functions for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['DOM_LUCLASS'] = d.LUC.apply(dom_landuse) # This won't work because work is needed above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is how to plot it to check your handiwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure(figsize=(8,11))\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "d.plot(ax=ax1, column='DOM_LUCLASS', cmap='tab20b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you understand the overall plan. If you are unsure about anything, then ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions\n",
    "Once you have all the parts working, in the various cells above, double check everything by resetting the notebook and running everything from a newly reopened copy.\n",
    "\n",
    "Then put everything (dictionary, functions, commands to run the functions) in the single cell below.\n",
    "\n",
    "Also, for this assignment, **add comments to your code**. This is to help me assess how well you understand what you are doing, and will be an important part of the grading. You don't need to comment every single line, you just need to give some indication you know what you are doing at each stage.\n",
    "\n",
    "Finally, save the notebook, ensuring your name is included in the filename, and submit via the dropbox provided on Blackboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assemble all the code needed to do the processing in this cell\n",
    "## Make sure to comment your code, so I can tell what you think you are doing\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "import geopandas\n",
    "\n",
    "## --------------------------------------------------------------------------\n",
    "## Initialise the dictionary here:\n",
    "## --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "## --------------------------------------------------------------------------\n",
    "## Provide function definitions here:\n",
    "## --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "## --------------------------------------------------------------------------\n",
    "## And now run the code\n",
    "## --------------------------------------------------------------------------\n",
    "\n",
    "# Start by reading the data\n",
    "d = geopandas.read_file('wairarapa_s_hawkes_bay.geojson')\n",
    "\n",
    "# Over to you!\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
